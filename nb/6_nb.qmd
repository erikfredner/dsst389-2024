---
title: "Relative Frequencies"
subtitle: "DSST389: Advanced Data Science"
author: "Erik Fredner"
institute: "University of Richmond"
date: today
echo: false
format:
  html:
    anchor-sections: true
    code-tools: false
    code-link: true
    embed-resources: true
    link-external-icon: true
    link-external-newwindow: true
    number-sections: true
    smooth-scroll: true
    toc: true
editor:
  markdown:
    wrap: 72
---

## Environment

Run the following in a code chunk or your console to clean up your environment:

```r
if (interactive()) {
  rstudioapi::restartSession(clean = TRUE)
}
```

You may need to install some new libraries and their dependencies:

```{r}
if (!requireNamespace("tidytext", quietly = TRUE)) {
  install.packages("tidytext")
}

if (!requireNamespace("gutenbergr", quietly = TRUE)) {
  install.packages("gutenbergr")
}

if (!requireNamespace("janeaustenr", quietly = TRUE)) {
  install.packages("janeaustenr")
}
```

Then, import needed libraries:

```{r}
#| label: libraries

library(tidyverse)
library(ggrepel)
library(tidytext)
library(gutenbergr)
library(janeaustenr)
library(scales)

theme_set(theme_minimal())

set.seed(123)
```

## Data

Today, we're going to continue working with the novels of [Jane Austen](https://en.wikipedia.org/wiki/Jane_Austen), author of *Pride and Prejudice* (1813). These are part of [the `janeaustenr`package](https://github.com/juliasilge/janeaustenr).

We are also going to work with some texts from [Project Gutenberg](https://en.wikipedia.org/wiki/Project_Gutenberg).

:::{.callout-important}
If you have never heard of Project Gutenberg before, spend a couple of minutes [looking at the website](https://gutenberg.org/). Gutenberg contains digital texts that volunteers have transcribed. For example, here is their copy of [Lincoln's Gettysburg Address](https://gutenberg.org/ebooks/4).
:::

### Set up

I'm going to set up Austen's books for you in the cell below:

```{r}
books <- austen_books() |>
  group_by(book) |>
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(
      text,
      regex("^chapter [\\divxlc]", ignore_case = TRUE)
    ))
  ) |>
  ungroup()
```

Don't worry if some of these functions (e.g., `cumsum()`, `regex()`) don't look familiar. We will cover them when you need to use them.

## Analysis

### Tokenizing Austen

As before, we are going to tokenize Austen's novels into a variable called `tidy_books`. After tokenizing, remove the stop words.

```{r}
#| label: q-tokenize-austen

tidy_books <- books |>
  unnest_tokens(output = word, input = text) |>
  anti_join(stop_words, join_by(word))

tidy_books |>
  slice_sample(n = 5)
```

### Getting new texts

The `gutenbergr` package ([documentation](https://docs.ropensci.org/gutenbergr/)) makes it simple to download texts from Project Gutenberg (PG).

The `gutenberg_download()` function downloads texts from PG based on their ID number. You can find the ID number in two ways. One way is to use the `gutenberg_works()` function, which finds texts by name:

```{r}
gutenberg_works() |>
  filter(title == "Wuthering Heights")
```

However, in my experience, this is a bit unreliable. You can also find a work's ID number by Googling the work's name and Project Gutenberg, then you can find the ID in the URL. For example, if you wanted to get *Moby-Dick* (1851), you can find the ID in the highlighted part of the URL:

https://www.gutenberg.org/ebooks/<mark>2701</mark>

Pick *any* text from Project Gutenberg and find its ID number. Then, try to use `gutenbergr` to download that text and save it into a variable.

```{r}
#| label: q-download-pg

text <- gutenberg_download(gutenberg_id = 4)

text
```

### Word frequencies

A common task in text mining is to look at word frequencies, just like we have done above for Jane Austen’s novels, and to compare frequencies across different texts. We can do this intuitively and smoothly using tidy data principles. We already have Jane Austen’s works; let’s get two more sets of texts to compare to. First, let’s look at some science fiction and fantasy novels by H.G. Wells, who lived in the late 19th and early 20th centuries. Let’s get *The Time Machine*, *The War of the Worlds*, *The Invisible Man*, and *The Island of Doctor Moreau*. We can access these works using `gutenberg_download()` and the Project Gutenberg ID numbers for each novel.

```{r}
hgwells <- gutenberg_download(
  c(35, 36, 5230, 159),
  mirror = "http://mirror.csclub.uwaterloo.ca/gutenberg"
)

hgwells
```

(We are using the specific `mirror` identified above because the default mirror is not currently working for all texts.)

You will notice that there is a `gutenberg_id` column in the tibble that corresponds to each book.

Now let’s get some well-known works of the Brontë sisters, whose lives overlapped with Jane Austen’s somewhat but who wrote in a rather different style. Let’s get *Jane Eyre*, *Wuthering Heights*, *The Tenant of Wildfell Hall*, *Villette*, and *Agnes Grey*. We will again use the Project Gutenberg ID numbers for each novel and access the texts using `gutenberg_download()`.

```{r}
bronte <- gutenberg_download(
  c(1260, 768, 969, 9182, 767),
  mirror = "http://mirror.csclub.uwaterloo.ca/gutenberg"
)

bronte
```

#### Tokenizing Wells and Brontë

Tokenize `hgwells` and `bronte`. Remove all stop words after tokenization. Save them into variables called `tidy_hgwells` and `tidy_bronte` respectively.

```{r}
#| label: q-tokenize-2

tidy_hgwells <- hgwells |>
  unnest_tokens(word, text) |>
  anti_join(stop_words, join_by(word))

tidy_bronte <- bronte |>
  unnest_tokens(word, text) |>
  anti_join(stop_words, join_by(word))
```

To confirm that you have done this correctly, print the five most frequent words from each of the new `tidy_` variables you created.

```{r}
#| label: q-mfw

tidy_bronte |>
  count(word, sort = TRUE) |>
  slice_head(n = 5)

tidy_hgwells |>
  count(word, sort = TRUE) |>
  slice_head(n = 5)
```

Now, we are going to put all three of our `tidy_` variables into a single table for analysis and visualization.

We can combine these data sets using [the `bind_rows()` function](https://dplyr.tidyverse.org/reference/bind_rows.html). When you have multiple data sets that you would like to combine into a single table, you can use `bind_rows()` to "stack" them on top of each other.

Before we combine them, we need to preserve some *metadata*, specifically the authors' names as we are going to compare their works to each other. Overwrite each of the `tidy_` variables above with an updated version of the data set that contains the author's name as a column. This will allow us to attribute every line of text to a specific author.

To confirm that you have done this correctly, print the first five rows from `tidy_bronte` with the updated column.

```{r}
#| label: q-author-meta

tidy_books <- tidy_books |>
  mutate(author = "Jane Austen")

tidy_hgwells <- tidy_hgwells |>
  mutate(author = "H.G. Wells")

tidy_bronte <- tidy_bronte |>
  mutate(author = "The Brontë Sisters")

tidy_bronte |>
  slice_head(n = 5)
```

Now, bind your updated `tidy_` data sets together, keeping only the `author` and `word` columns. Save these bound rows into a variable called `frequency`.

Then, find out how many rows you have in `frequency` to confirm that all of the words are present.

```{r}
#| label: q-bind

frequency <- bind_rows(tidy_bronte, tidy_hgwells, tidy_books) |>
  select(author, word)

frequency |>
  count()
```

#### Text cleaning

Text cleaning tasks are common in text analysis. The tokenizer handles many of them for us, but not all. We can remove some errors in this particular data set with the following line:

```r
str_extract(word, "[a-z']+")
```

This line of code looks at the text stored in `word` and picks out the first group of characters that are either lowercase letters (from a to z) or apostrophes. In other words, it extracts a continuous string made up only of those characters. For example, if word were "can't-stop", it would return "can't" because that’s the first sequence made up only of lowercase letters and the apostrophe.

Clean the values in the column `word` in `frequency` using the line above. Overwrite `frequency` with the updated values.

```{r}
#| label: q-cleaning

frequency <- frequency |>
  mutate(word = str_extract(word, "[a-z']+"))
```

#### Relative frequencies

When comparing multiple texts to each other, we need to account for the fact that the texts are going to be of different lengths.

In the case of the present work, we are trying to compare the language used by each of these *authors*, so we need to calculate the relative frequency of each of their words as used in the corpus in order to compare their frequencies to one another.

Calculate the relative frequency with which each author in the corpus uses each word in the corpus. Drop column containing the words' raw frequencies from the resulting table.

Once you are confident that you have this right, overwrite `frequency` with the relative frequencies, and print 2 random rows from each author to confirm.

```{r}
#| label: q-rel-freq

frequency <- frequency |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(!n)

frequency |>
  slice_sample(n = 2)
```

#### Double pivot

Our goal now is to compare Jane Austen's relative frequencies to those of both H.G. Wells and the Brontë sisters. To do this, we are going to want an unusual data structure: One column containing Austen's relative frequencies, and another column containing the other authors' relative frequencies of the same word. This is what it will look like:

| word   | Jane Austen  | author         | proportion  |
|--------|------------:|---------------|------------:|
| a      | 0.00000919  | Brontë Sisters | 0.00000797  |
| a      | 0.00000919  | H.G. Wells     | NA          |

The reason we need the data structured this way is that we are going to create a faceted plot comparing Austen to each of the authors in `author`. Sometimes, data reshaping requires multiple pivots; you are not always going from wide to long or vice versa.

1. Pivot wider the names from author and take the values from proportion.
2. Then, only pivot longer Wells and the Brontës, using the column names given above.
3. Calculate the absolute value of the difference between Austen's usage and each of the other authors' usage, and put that into a new column called `austen_diff`
4. Once you are sure you have done this right, overwrite `frequency` and return the first five rows.

```{r}
#| label: q-double-pivot

frequency <- frequency |>
  pivot_wider(names_from = author, values_from = proportion) |>
  pivot_longer(
    c("The Brontë Sisters", "H.G. Wells"),
    names_to = "author", values_to = "proportion"
  ) |>
  mutate(austen_diff = abs(`Jane Austen` - proportion))

frequency |>
  slice_head(n = 5)
```

#### Plot

Now, we are ready to plot these differences!

1. **Create the Base Plot with Mapped Aesthetics**  
   Start by calling `ggplot()` on your `frequency` data and map the key variables:
   - **x:** Use the other authors’ relative frequency.
   - **y:** Use Jane Austen’s relative frequency.
   - **color:** Map to `austen_diff`.

2. **Add a Reference Line**  
   Add a diagonal reference line with `geom_abline()`.  
   - This dashed line (using `linetype = "dashed"`) helps visualize where the two frequencies would be equal.

3. **Plot the Data Points with Jittering**  
   To avoid overplotting, use `geom_jitter()`. Make the points semi-transparent. Add a small amount of random noise to spread the points in both x and y directions using the `width` and `height` arguments.

4. **Conditionally Label Significant Points**  
   Use `geom_text_repel()` to label points. To match my plot, only label points where `austen_diff` is at least 0.002. Play around with this value.

5. **Apply Logarithmic Scales and Format the Axes**  
   - Use `scale_x_log10()` and `scale_y_log10()`.
   - Format the tick labels as percentages with `percent_format()` to make the proportions easier to interpret.

6. **Use the Viridis Color Scale**  
   - Apply the viridis color scale to `austen_diff`.

7. **Facet by Author**  
  To compare Jane Austen’s usage against each other author separately, use `facet_wrap()` to split the plot into panels.

8. **Add Axis Labels**  
   Finally, use `labs()` to clean up the axis labels. In my plot, the x-axis label is set to `NULL`.

```{r}
#| label: q-plot
#| warning: false

frequency |>
  ggplot(aes(
    x = proportion,
    y = `Jane Austen`,
    color = austen_diff
  )) +
  geom_abline(color = "black", alpha = 0.5, linetype = "dashed") +
  geom_jitter(alpha = 0.3, width = 0.3, height = 0.3) +
  geom_text_repel(
    aes(label = if_else(austen_diff >= 0.002, word, NA_character_)),
    size = 3
  ) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_viridis_c() +
  facet_wrap(vars(author), ncol = 2) +
  labs(x = NULL, y = "Jane Austen")
```
