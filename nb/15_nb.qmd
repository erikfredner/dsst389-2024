---
title: "ENET and GBT"
subtitle: "DSST389: Advanced Data Science"
author: "Erik Fredner"
institute: "University of Richmond"
date: today
execute:
  echo: false
  warning: true
format:
  html:
    anchor-sections: true
    code-tools: false
    code-link: true
    embed-resources: true
    link-external-icon: true
    link-external-newwindow: true
    number-sections: true
    smooth-scroll: true
    toc: true
editor:
  markdown:
    wrap: 72
---

## Environment

### Clean

Run the following code chunk to clean up your environment:

```{r}
#| eval: false
#| label: clean-env

if (interactive()) {
  rstudioapi::restartSession(clean = TRUE)
}
```

### Install

You may need to update or install some packages:

```{r}
#| label: get-packages

packages <- c(
  "tidyverse", "tidymodels", "textrecipes", "kknn",
  "xgboost", "glmnet", "corrplot", "parallel", "future"
)

for (pkg in packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
  }
}
```

### Load

Import needed libraries and apply settings:

```{r}
#| label: libraries-settings

for (pkg in packages) {
  library(pkg, character.only = TRUE)
}

theme_set(theme_minimal())

set.seed(123)

all_cores <- parallel::detectCores()
plan(multisession, workers = all_cores)
```

The last two lines in this chunk *parallelize* your code, which can be useful for computationally intensive tasks like model fitting. Note that it will be difficult to use your computer for other tasks while this is running.

## ENET and GBT

In this notebook, we will be practicing using elastic net (ENET) regularization and gradient boosted trees (GBT).

## Data

You will be working with a new data set in this notebook. We will discuss how to apply these models to text data in a future notebook.

### Wine

The UC Irvine machine learning repository [maintains](https://archive.ics.uci.edu/dataset/186/wine+quality) a donated data set about the quality of Portuguese wines. The goal is to model wine quality based on physicochemical tests of the wine itself.

#### Data dictionary

| Variable Name          | Role     | Type        | Description            | Missing Values |
|------------------------|----------|-------------|------------------------|----------------|
| `fixed_acidity`        | Feature  | Continuous  |                        | no             |
| `volatile_acidity`     | Feature  | Continuous  |                        | no             |
| `citric_acid`          | Feature  | Continuous  |                        | no             |
| `residual_sugar`       | Feature  | Continuous  |                        | no             |
| `chlorides`            | Feature  | Continuous  |                        | no             |
| `free_sulfur_dioxide`  | Feature  | Continuous  |                        | no             |
| `total_sulfur_dioxide` | Feature  | Continuous  |                        | no             |
| `density`              | Feature  | Continuous  |                        | no             |
| `pH`                   | Feature  | Continuous  |                        | no             |
| `sulphates`            | Feature  | Continuous  |                        | no             |
| `alcohol`              | Feature  | Continuous  |                        | no             |
| `quality`              | Target   | Integer     | score between 0 and 10 | no             |
| `type`                | Other    | Categorical | red or white           | no             |

### Load data

```{r}
#| label: load-wine

wine <- read_csv("../data/wine.csv")
```

## ENET Wine

### Exploratory data analysis

When modeling a dataset, exploratory data analysis is always a good first step. In this case, we will be modeling wine `quality`. Create bar plots showing the relationship of wine quality by wine type (red vs. white). Use `#800e13` as the color for red wine and `#f4d58d` for white wine. Make sure to include all of the quality ratings on the x-axis. You can do this with the argument `position = "dodge"`.

```{r}
#| label: q-eda-quality

wine |>
  ggplot(aes(x = quality, fill = type)) +
  geom_bar(color = "black", position = "dodge") +
  scale_fill_manual(values = c("#800e13", "#f4d58d")) +
  scale_x_continuous(breaks = wine |> distinct(quality) |> pull()) +
  labs(title = "Wine quality by type")
```

As you can see we have more observations of white wine than red. Recreate the bar chart above using proportional values between the two groups across all observations. You can do this with the argument `position = "fill"`.

```{r}
#| label: q-eda-quality-prop-all

wine |>
  ggplot(aes(x = quality, fill = type)) +
  geom_bar(color = "black", position = "fill") +
  scale_fill_manual(values = c("#800e13", "#f4d58d")) +
  scale_x_continuous(breaks = wine |> distinct(quality) |> pull()) +
  labs(title = "Wine quality by type (proportional)")
```

Now, create a plot showing the distribution of quality ratings *within* groups. That is, among red wines, what percentage received of red wines received each rating?

```{r}
#| label: q-eda-quality-prop-group

wine |>
  count(type, quality) |>
  group_by(type) |>
  mutate(prop = n / sum(n)) |>
  ggplot(aes(x = quality, y = prop, fill = type)) +
  geom_col(color = "black", position = "dodge") +
  scale_fill_manual(values = c("#800e13", "#f4d58d")) +
  scale_x_continuous(breaks = wine |> distinct(quality) |> pull()) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Percentages of wines by type and quality",
    x = "Quality",
    y = "Percentage of wines by type"
  )
```

Finally, we're going to create a couple of simple linear models looking at the relationship between wine quality and any two variable of your choosing in the dataset. Note that this is going to be partially compromised by the fact that `quality` is discrete. I have chosen alcohol and residual sugar for my plots, but you may choose other variables of interest. You will note that I have used `geom_jitter()` to better show the number of observations under the model.

```{r}
#| label: q-eda-lm-1

wine |>
  ggplot(aes(x = alcohol, y = quality, colour = type)) +
  geom_jitter(alpha = 0.1) +
  geom_smooth(method = "lm") +
  scale_color_manual(values = c("#800e13", "#f4d58d")) +
  scale_y_continuous(breaks = wine |> distinct(quality) |> pull()) +
  labs(title = "Wine quality by alcohol content")
```

In my case, this appears to show that there is a positive relationship between alcohol content and wine quality for both red and white wine.

Is the same true for residual sugars? My plot excludes the top percentile of residual sugars since there are a small number of outliers.

```{r}
#| label: q-eda-lm-2

wine |>
  filter(`residual sugar` < quantile(`residual sugar`, 0.99)) |>
  ggplot(aes(x = `residual sugar`, y = quality, colour = type)) +
  geom_jitter(alpha = 0.1) +
  geom_smooth(method = "lm") +
  scale_color_manual(values = c("#800e13", "#f4d58d")) +
  labs(title = "Wine quality by residual sugars")
```

Residual sugars appear to have a more complex relationship to quality than alcohol does.

Finally, it is a good idea to understand how values in your data correlate with each other, as lasso and elastic net regularization can be sensitive to multicollinearity.

Calculate the correlations among all numeric columns in the wine data, and then plot those correlations using `corrplot()`.

```{r}
#| label: q-eda-corr

wine |>
  select(-type) |>
  cor() |>
  corrplot()
```

#### EDA reflection

What do you observe about the distribution of quality ratings between red and white wines from these exploratory analyses? *Write two sentences below:*



### Modeling quality

Now, we are going to create an *elastic net* (ENET) to see if we can predict wine quality based on the other variables in the dataset. As you have seen, there are differences among the rating distributions between white and red wines, so we will also use the `type` variable as a predictor, too.

#### Split the data

Use an 80/20 train/test split. We stratify on the continuous variable `quality` to maintain similar outcome distributions in training and testing sets. Return your split object.

```{r}
#| label: q-split

wine_split <- initial_split(wine, prop = 0.8, strata = quality)
wine_train <- training(wine_split)
wine_test <- testing(wine_split)

wine_split
```

#### Set up ENET model

Tune both the `penalty` and `mixture` arguments to a linear regression function and use the `glmnet` engine.

```{r}
#| label: q-enet-model

enet_model <- linear_reg(penalty = tune(), mixture = tune()) |>
  set_mode("regression") |>
  set_engine("glmnet")
```

#### Create a recipe

Specify `quality ~ .` as the formula (predict quality from all other predictors). Normalize numeric predictors and dummy‐encode nominal predictors. Return your recipe object.

```{r}
#| label: q-enet-recipe

enet_recipe <- recipe(quality ~ ., data = wine_train) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors())

enet_recipe
```

#### Create an elastic net workflow

Use the recipe and model established above. Return your workflow object.

```{r}
#| label: q-enet-workflow

enet_wf <- workflow() |>
  add_recipe(enet_recipe) |>
  add_model(enet_model)

enet_wf
```

#### Create cross-validation folds

Use 10‐fold cross‐validation stratified by quality. Return your folds object.

```{r}
#| label: q-enet-folds

enet_folds <- vfold_cv(wine_train, v = 10, strata = quality)
enet_folds
```

#### Tune over a grid of penalty and mixture values

Tune over a grid of possible penalty values. Try 50 different combinations of {`penalty`, `mixture`}. Pass the `metric` argument the `metric_set()` function containing the RMSE and MAE metrics.

```{r}
#| label: q-enet-tune-grid

tuned_enet_results <- tune_grid(
  enet_wf,
  resamples = enet_folds,
  grid = 50,
  metrics = metric_set(rmse, mae)
)
```

#### Visualize the tuning process

Call `autoplot()` on your tuned results to visualize the tuning process.

```{r}
#| label: q-enet-autoplot

autoplot(tuned_enet_results)
```

Based on the autoplot, which values of lambda appear to be best? How do you know?

#### Identify the best parameters programmatically

Select the best parameters based on the RMSE metric. Return those parameters.

```{r}
#| label: q-enet-select
best_enet <- select_best(tuned_enet_results, metric = "rmse")
best_enet
```

#### Finalize the workflow

Finalize the workflow with the the best (penalty, mixture).

```{r}
#| label: q-enet-final-workflow

final_enet_wf <- finalize_workflow(enet_wf, best_enet)
```

#### Fit on the training set

Train the final elastic net model on your training data.

```{r}
#| label: q-enet-train

final_enet_fit <- final_enet_wf |>
  fit(data = wine_train)
```

#### Predict on the testing set

Use your fit model to make predictions on your testing data. Then, print out your prediction metrics.

```{r}
#| label: q-enet-predict

final_enet_preds <- final_enet_fit |>
  predict(new_data = wine_test) |>
  bind_cols(wine_test)

final_enet_preds |>
  metrics(truth = quality, estimate = .pred)
```

#### Review coefficients

Output a table of the coefficients from your final model, sorted by the absolute value of their estimate.

```{r}
#| label: q-enet-coefs

final_enet_fit |>
  extract_fit_parsnip() |>
  tidy() |>
  arrange(desc(abs(estimate)))
```

#### ENET interpretation

What are the most important predictors in your elastic net model? *Write a sentence below:*

How would you know if this model is performing well? *Write a sentence below:*

If the model is not performing well, what might you do to improve it? *Write a sentence below:*

## GBT

Now, we're going to use a gradient boosted tree (GBT) model to predict wine quality. Will it do better than the elastic net model?

### Review

If you would like to learn more about how GBT works, I recommend watching these videos in this order:

1. [Gradient Boosting regression](https://www.youtube.com/watch?v=3CC4N4z3GJc)
2. [Gradient Boosting classification](https://www.youtube.com/watch?v=jxuNLH5dXCs)
3. [XGBoost regression](https://www.youtube.com/watch?v=OtD8wVaFm6E)
4. [XGBoost classification](https://www.youtube.com/watch?v=8b1JEDvenQU)

You may use your existing `wine_train` and `wine_test` data sets for this section.

### Create an XGBoost recipe

In creating your recipe, note that not all steps shown in the slides apply to the wine data! You can tell from my outputs which are required. Return your recipe object.

```{r}
#| label: q-xgb-recipe

xgb_recipe <- recipe(quality ~ ., data = wine_train) |>
  step_dummy(all_nominal_predictors()) |>
  step_nzv(all_predictors())

xgb_recipe
```

### Set up cross-validation

To reduce run time on your machine, use 5‐fold cross‐validation stratified by quality. Return your fold object.

```{r}
#| label: q-xgb-folds

wine_folds <- vfold_cv(wine_train, v = 5, strata = quality)

wine_folds
```

### Specify the XGBoost model

Use `boost_tree()` to set up an XGBoost model for regression. Return your model object.

What do each of the following hyperparameters—`trees`, `min_n`, `tree_depth`, `learn_rate`, and `loss_reduction`—do in terms of model complexity and training? Look at the documentation for `boost_tree()` to find out.

```{r}
#| label: q-xgb-model

xgb_model <- boost_tree(
  trees = tune(),
  learn_rate = tune(),
  tree_depth = tune(),
  min_n = tune(),
  loss_reduction = tune()
) |>
  set_engine("xgboost", objective = "reg:squarederror") |>
  set_mode("regression")

xgb_model
```

### Define a tuning grid

Below, we use `grid_space_filling()` to define a grid of hyperparameters to search over.

I have defined these ranges for this model to avoid the problem of *overfitting*. Specifically, with a low `loss_reduction` value, the wine data tends to overfit on the training data.

Note that some of the values given in these ranges are log-transformed (e.g., `learn_rate`).

If you would like to see the model overfit for yourself, eliminate all of the `range` arguments below and only leave each grid item as the function (e.g., `trees()`). When you tune on that grid, you will almost certainly end up with a model that performs very well on the training data but comparatively poorly on the testing data.

```{r}
#| label: xgb-grid

xgb_grid <- grid_space_filling(
  trees(range = c(200, 700)),
  tree_depth(range = c(3, 10)),
  learn_rate(range = c(-3, 0)),
  min_n(range = c(5, 25)),
  loss_reduction(range = c(0.5, 1)),
  size = 50
)

xgb_grid
```

### Create a workflow

Combine your recipe and model into a workflow object. Return that object.

```{r}
#| label: q-xgb-workflow

xgb_wf <- workflow() |>
  add_recipe(xgb_recipe) |>
  add_model(xgb_model)

xgb_wf
```

### Tune hyperparameters

Use `tune_grid()` to tune your XGBoost model over the grid of hyperparameters defined earlier. Collect RMSE, $R^2$, and MAE metrics.

:::{.callout-warning}
This takes about 1 minute to run on my machine.
:::

```{r}
#| label: q-xgb-tune

xgb_tune <- tune_grid(
  xgb_wf,
  resamples = wine_folds,
  grid = xgb_grid,
  metrics = metric_set(rmse, rsq, mae)
)

show_notes(xgb_tune)
```

### Select the best hyperparameters

Return the object with your best parameters.

```{r}
#| label: q-xgb-select

best_params <- select_best(xgb_tune, metric = "rsq")
best_params
```

### Finalize the workflow

Finalize your workflow with your best parameters and fit it on the training set. Return your fit object.

```{r}
#| label: q-final-xgb

final_wf <- finalize_workflow(xgb_wf, best_params)

final_fit <- final_wf |> fit(data = wine_train)

final_fit
```

### Evaluate training data performance

Retrieve the `metrics()` from your fitted model.

How does your model perform on the data it was trained on?

```{r}
#| label: q-xgb-train-metrics

train_preds <- predict(final_fit, wine_train) |>
  bind_cols(wine_train)

train_preds |>
  metrics(truth = quality, estimate = .pred)
```

### Evaluate testing data performance

This question is the same as above, but using the testing data.

How does your model perform on testing data as compared to training data?

```{r}
#| label: q-xgb-test-metrics

test_preds <- predict(final_fit, wine_test) |>
  bind_cols(wine_test)

test_preds |>
  metrics(truth = quality, estimate = .pred)
```

#### Plot residuals

Are your errors well distributed around zero? Manually calculate your residuals by taking the difference between the target and the prediction, and then plot them using `geom_histogram`.

You can use the line below to add a vertical red line to highlight the point of zero error:

```{r}
#| eval: false

geom_vline(xintercept = 0, linetype = "dashed", color = "red")
```


```{r}
#| label: q-xgb-plot-residuals

test_residuals <- test_preds |>
  mutate(residual = quality - .pred)

ggplot(test_residuals, aes(x = residual)) +
  geom_histogram(bins = 30, alpha = 0.5) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Residual")
```

#### Feature importance

Extract the ten most important features by gain from the model's fit engine.

```{r}
#| label: q-xgb-feature-importance

final_model <- final_fit |>
  extract_fit_engine()

importance_df <- xgb.importance(model = final_model) |>
  as_tibble() |>
  arrange(desc(Gain)) |>
  slice_head(n = 10)

importance_df
```

Which features does the model consider most important with respect to gain? To what extent do those features align with your understanding about what people value in wine?
